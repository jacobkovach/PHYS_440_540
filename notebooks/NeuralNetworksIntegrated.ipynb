{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Neural Networks I\n",
    "G. Richards\n",
    "(2016, 2018, 2020, 2022)\n",
    "[Ivezic 9.8](https://www.astroml.org/book_figures/chapter9/index.html) and [Geron](https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1492032646/ref=sr_1_5?dchild=1&keywords=machine+learning&qid=1596499152&sr=8-5).   With updates to my own class from [Stephen Taylor's class at Vanderbilt](https://github.com/VanderbiltAstronomy/astr_8070_s22).\n",
    "\n",
    "I found this video series particularly helpful in trying to simplify the explanation https://www.youtube.com/watch?v=bxe2T-V8XRs. \n",
    "\n",
    "\n",
    "- [Textbook](http://press.princeton.edu/titles/10159.html) Chapter 9.\n",
    "- Many blogs and videos.\n",
    "- Free online book! http://neuralnetworksanddeeplearning.com/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Contents\n",
    "\n",
    "Loss Functions, Gradient Descent, and AdaBoost are in Classification3.  Add them here??\n",
    "\n",
    "\n",
    "* [Neural networks](#one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Before we start today, we need to install some new software.  Go ahead and do this while you are waiting for lecture to start.\n",
    "\n",
    "On the command line:\n",
    "    \n",
    "% python3 -m pip install --upgrade tensorflow\n",
    "\n",
    "% pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfds\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorFlow version:\u001b[39m\u001b[38;5;124m\"\u001b[39m, tf\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num CPUs Available: \", len(tf.config.experimental.list_physical_devices('CPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Before lecture today, please go to https://playground.tensorflow.org/\n",
    "\n",
    "Try the default. Note how the first layer identifies simple patterns and the second layer combines those to make more complex patterns. It also finds a solution quite quickly. (Note also that it won't stop on its own. Hit pause when you are happy with the solution it has converged on.)\n",
    "Try a ReLU activation function. Much faster, but with a \"boxy\" solution.\n",
    "See what happens when there is only 1 hidden layer with 3 neurons. Reset and run it multiple times.\n",
    "Compare learning rate 0.001 to 1.0.\n",
    "Now try just 2 neurons (with learning rate back at 0.3).\n",
    "Now try 8 neurons.\n",
    "Lastly try the spiral dataset with 4 hidden layers, each with 8 neurons. Run it for at least 1000-1500 epochs -- until it gets the answer \"right\" (make sure that your computer is plugged in and properly cooled!) This illustrates the vanishing gradient problem.\n",
    "Do this again after lecture.\n",
    "See Problem 10.1 in Geron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "[Artificial Neural Networks](https://en.wikipedia.org/wiki/Artificial_neural_network) are a simplified computation architecture based loosely on the real neural networks found in brains. \n",
    "\n",
    "![Neuron example](https://4.bp.blogspot.com/-Z5LfY6yoIcE/U-OFKWHoAbI/AAAAAAAAAKo/ytH6BzDLeo4/s1600/Picture-533.png)\n",
    "\n",
    "In reality, what we are going to explore is a **[multi-layer perceptron](https://en.wikipedia.org/wiki/Multilayer_perceptron)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the image below, \n",
    "- the circles on the ***left*** represent the **features/attributes** of our input data, $X$, which here is 3 dimensional.  \n",
    "- the circles in the ***middle*** represent the **neurons**. They take in the information from the input and, based on some criterion decide whether or not to \"fire\". These middle layers are called \"**hidden layers**\".\n",
    "- the collective results of the neurons in the hidden layer produce the **output**, $y$, which is represented by the circles on the ***right***, which here is 2 dimensional result.  \n",
    "- the lines connecting the circles represent the synapses.  \n",
    "\n",
    "This is a simple example with just one layer of neurons; however, there can be many layers of neurons.\n",
    "\n",
    "![Cartoon of Neural Network](https://upload.wikimedia.org/wikipedia/commons/thumb/e/e4/Artificial_neural_network.svg/500px-Artificial_neural_network.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here are two graphics from an [article](https://towardsdatascience.com/artificial-intelligence-vs-machine-learning-vs-deep-learning-2210ba8cc4ac describing the relationship between artificial inteligence, machine learning and deep learning.\n",
    "\n",
    "![MLvsDL1](https://miro.medium.com/max/1060/0*R53mzDRJXZ8l6idL)\n",
    "\n",
    "![MLvsDL2](https://miro.medium.com/max/1400/0*2V2i5DbamWhswRV6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Back to understanding this architecture.\n",
    "\n",
    "![Cartoon of Neural Network](https://upload.wikimedia.org/wikipedia/commons/thumb/e/e4/Artificial_neural_network.svg/500px-Artificial_neural_network.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The job of a synapse is to take input values and multiply them by some **weight**, $w$, and add a **bias**, $b$, before passing them to the neuron (hidden layer):\n",
    "\n",
    "$$z = \\sum_i w x_i + b$$\n",
    "\n",
    "The bias determines the input level at which the neuron \"fires\". It is always present, and unique to each neuron, but we'll set that to zero for the sake of simplicity here.\n",
    "\n",
    "The neuron then sums up the inputs from all of the synapses connected to it and applies an \"**activation function**\", e.g., a **[sigmoid](https://en.wikipedia.org/wiki/Sigmoid_function) activation function**.\n",
    "\n",
    "$$a = \\frac{1}{1+e^{-z}}.$$\n",
    "\n",
    "![Sigmoid Function](https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/500px-Logistic-curve.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What the neural network does is to learn the weights of the synapses that are needed to produce an accurate model of $y_{\\rm train}$.\n",
    "\n",
    "![Ivezic Figure 9.17](https://www.astroml.org/_images/fig_neural_network_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Rather than think about the inputs individually, we can write this process in matrix form as\n",
    "$$Z^{(2)} = X W^{(1)}$$\n",
    "\n",
    "If $D$ is the number of attributes and $H$ is the number of neurons in the hidden layer, then $X$ is an $N\\times D$ matrix, while $W^{(1)}$ is a $D\\times H$ matrix.  The result, $Z^{(2)}$, is then an $N\\times H$ matrix.\n",
    "\n",
    "We then apply the activation function to each entry of $Z^{(2)}$ independently: \n",
    "$$A^{(2)} = f(Z^{(2)}),$$\n",
    "where $A^{(2)}$ is the output of the neurons in the hidden layer and is also $N\\times H$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "These values are then the inputs for the next set of synapses, where we multiply the inputs by another set of weights, $W^{(2)}:$\n",
    "$$Z^{(3)} = A^{(2)} W^{(2)},$$\n",
    "\n",
    "where $W^{(2)}$ is an $H\\times O$ matrix and $Z^{(3)}$ is an $N\\times O$ matrix with $O$-dimensional output.\n",
    "\n",
    "Another activation function is then applied to $Z^{(3)}$ to give\n",
    "$$\\hat{y} = f(Z^{(3)}),$$\n",
    "which is our estimator of $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Following my previous examples, say we have $N=100$ skeletons for which we have measured \n",
    "* tibia length\n",
    "* femur lenght\n",
    "* ulna length\n",
    "\n",
    "for which we know their species and gender.\n",
    "\n",
    "Then we are going to use this to predict the species and gender of an unknown skeleton."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The neural network then essentially boils down to determining the weights of the synapses, which are usually initialized randomly.\n",
    "\n",
    "We do that by minimizing the cost function (which compares the true values of $y$ to our predicted values).  Typically an MSE cost:\n",
    "$$ {\\rm Cost} = J = \\sum\\frac{1}{2}(y - \\hat{y})^2.$$\n",
    "\n",
    "Let's take a minute to talk about loss functions in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "As we saw above, that would be a cost function for regression (where we have only one output node).  For classification, we'd use one of the examples above (but ideally one that is differentiable as we'll see later)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Loss Functions\n",
    "\n",
    "**GTR: This part is updated in Classification3 for 2022.  If keeping it here, update here instead (or in addition).**\n",
    "\n",
    "A [loss function](https://en.wikipedia.org/wiki/Loss_functions_for_classification) is like the cost functions that we discussed earlier, except for a single training example rather than the full data set.\n",
    "\n",
    "Whether you realize it or not, you are typically working with $l2$ loss functions:\n",
    "$$(y-f(x))^2,$$\n",
    "where the corresponding cost function is the mean of those for all $x_i$ or the Mean Squared Error (MSE).\n",
    "\n",
    "We also talked about $l1$ loss functions:\n",
    "$$|y-f(x)|,$$\n",
    "which is more robust to outliers.\n",
    "\n",
    "For regression we plot loss vs. $y-f(x)$, where ideally we want that to be zero and would assign that zero \"loss\".\n",
    "\n",
    "For classification we instead plot the loss vs. $y*f(x)$, where that is the known class (either $+1$ or $-1$) times the predicted value.  If that product is positive, we predict $+1$.  If it is negative, we predict $-1$.  \n",
    "\n",
    "We define the loss to be zero for $y*f(x)=1$, that is, when we have gotten the right answer.\n",
    "\n",
    "So what do the mean squared error (MSE or $l2$) and mean absolute error (MAE or $l1$) look like for classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Mathematical formulas for various loss functions\n",
    "def log_loss(raw_model_output):\n",
    "   return np.log(1+np.exp(-raw_model_output))\n",
    "\n",
    "def hinge_loss(raw_model_output):\n",
    "   return np.maximum(0,1-raw_model_output)\n",
    " \n",
    "def l2(raw_model_output):\n",
    "   return (raw_model_output-1)**2  \n",
    "\n",
    "def l1(raw_model_output):\n",
    "   return np.abs(raw_model_output-1)  \n",
    " \n",
    "def zero_one(raw_model_output):\n",
    "   return np.where(raw_model_output < 0, 1, 0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Create a grid of values and plot\n",
    "grid = np.linspace(-3,3,1000)\n",
    "plt.plot(grid, l2(grid), \"g\", label='l2')\n",
    "plt.plot(grid, l1(grid), \"brown\", label='l1')\n",
    "\n",
    "plt.fill_between([0,3],-0.02,5,\"b\",alpha=0.4)\n",
    "plt.fill_between([-3,0],-0.02,5,\"r\",alpha=0.5)\n",
    "plt.xlim([-3,3])\n",
    "plt.ylim([-0.02,5])\n",
    "plt.xlabel(\"y*f(x)\",fontsize=12)\n",
    "plt.ylabel(\"loss\",fontsize=12)\n",
    "plt.title(\"predict -1 (incorrect)         predict +1 (correct)\",fontsize=12)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Those would make sense if we plotted $y-f(x)$ as a value of $-1$ would be just as wrong as a value of $+1$.  \n",
    "\n",
    "When plotting $y*f(x)\\le1$ it kind of does something reasonable for $y*f(x)\\le1$.  However, look what happens at larger values (where we are even more confident that $y*f(x)$ is positive and that our class should be $+1$.  The loss goes **up**.  That's bad.\n",
    "\n",
    "Now, you may be wondering how $y*f(x)$ can be larger than 1.  Me too.  The internet is filled with useless non-answers.  But here's how this works.\n",
    "\n",
    "$f(x)$ isn't just a value between $-1$ and $1$, it is a function.  For example, let's say that our training data looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "xx = np.array([0.1,0.2,0.4,0.6,0.8,1.1,1.4,1.5])\n",
    "yy = np.array([-1,-1,-1,-1,1,1,1,1])\n",
    "\n",
    "#with plt.xkcd():\n",
    "if 1:\n",
    "    \n",
    "    fig = plt.figure(1)\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    # Move left y-axis and bottim x-axis to centre, passing through (0,0)\n",
    "    ax.spines['left'].set_position(('axes',0.045))\n",
    "    ax.spines['bottom'].set_position('center')\n",
    "\n",
    "    # Eliminate upper and right axes\n",
    "    ax.spines['right'].set_color('none')\n",
    "    ax.spines['top'].set_color('none')\n",
    "\n",
    "    # Show ticks in the left and lower axes only\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    \n",
    "    ax.plot(1, 0, \">k\", transform=ax.get_yaxis_transform(), clip_on=False)\n",
    "    ax.plot(0, 1, \"^k\", transform=ax.get_xaxis_transform(), clip_on=False)\n",
    "        \n",
    "    ax.scatter(xx,yy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now let's fit a linear model to the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(xx[:,None],yy)\n",
    "ypred = linreg.predict(grid[:,None])\n",
    "\n",
    "if 1:\n",
    "    \n",
    "    fig = plt.figure(1)\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    # Move left y-axis and bottim x-axis to centre, passing through (0,0)\n",
    "    ax.spines['left'].set_position(('axes',0.25))\n",
    "    ax.spines['bottom'].set_position('center')\n",
    "\n",
    "    # Eliminate upper and right axes\n",
    "    ax.spines['right'].set_color('none')\n",
    "    ax.spines['top'].set_color('none')\n",
    "\n",
    "    # Show ticks in the left and lower axes only\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    \n",
    "    ax.plot(1, 0, \">k\", transform=ax.get_yaxis_transform(), clip_on=False)\n",
    "    ax.plot(0, 1, \"^k\", transform=ax.get_xaxis_transform(), clip_on=False)\n",
    "    \n",
    "    ax.plot(grid,ypred)\n",
    "    ax.set_xlim([-1,3])\n",
    "    ax.set_ylim([-2,2])\n",
    "        \n",
    "    ax.scatter(xx,yy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We see that for $x$ greater than about 1.3, $f(x)$ can indeed be larger than 1 and so can $y*f(x)$, which is indicating an increased certainty of the $+1$ class. \n",
    "\n",
    "OK, so now we can understand the plot, but we still need a loss function that makes sense for classification.\n",
    "\n",
    "The first we'll try is the so-called [\"Zero-One\"](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.zero_one_loss.html) loss shown in **black**.  It is 1 for $yf(x)<0$ and 0 for $yf(x)>0$; thus the name.  You increment the loss function by 1 every time you make a wrong prediction.  It is just a count of the total number of mistakes.\n",
    "\n",
    "However, the Zero-One loss is hard to minimize, so instead we can try something that allows the loss to be continuous function in $y*f(x)$.  \n",
    "\n",
    "For example, the [Hinge Loss](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.hinge_loss.html), which looks like\n",
    "$${\\rm max}(0,1-y*f(x)),$$\n",
    "as plotted in **orange**.  Here there is no contribution to the loss for values $\\ge 1$, but there is an linearly increasing loss for smaller values.  So, it penalizes both wrong predictions and also correct predictions that have low confidence.\n",
    "\n",
    "A [logistic loss](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html#sklearn.metrics.log_loss) (also called the log loss and cross entropy loss) function has similar properties as shown in **blue**, but is smoother and has slightly less and less penalty for more and more confident $+1$ predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Create a grid of values and plot\n",
    "grid = np.linspace(-3,3,1000)\n",
    "#plt.plot(grid, log_loss(grid), label='logistic')\n",
    "plt.plot(grid, zero_one(grid), \"k\", label='0-1')\n",
    "plt.plot(grid, hinge_loss(grid), \"orange\", label='hinge')\n",
    "plt.plot(grid, log_loss(grid), \"b\", label='logistic')\n",
    "#plt.plot(grid, l2(grid), label='l2')\n",
    "#plt.plot(grid, l1(grid), label='l1')\n",
    "\n",
    "plt.fill_between([0,3],-0.02,5,\"b\",alpha=0.4)\n",
    "plt.fill_between([-3,0],-0.02,5,\"r\",alpha=0.5)\n",
    "plt.xlim([-3,3])\n",
    "plt.ylim([-0.02,5])\n",
    "plt.xlabel(\"y*f(x)\",fontsize=12)\n",
    "plt.ylabel(\"loss\",fontsize=12)\n",
    "plt.title(\"predict -1 (incorrect)         predict +1 (correct)\",fontsize=12)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For more see [Linear Classsifiers in Python course](https://learn.datacamp.com/courses/linear-classifiers-in-python).  Also\n",
    "\n",
    "https://datascience103579984.wordpress.com/2019/09/18/linear-classifiers-in-python-from-datacamp/\n",
    "\n",
    "https://towardsdatascience.com/common-loss-functions-in-machine-learning-46af0ffc4d23\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2019/08/detailed-guide-7-loss-functions-machine-learning-python-code\n",
    "\n",
    "http://www.datasciencecourse.org/notes/linear_classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "OK, back to trying to minimize the loss function by tweaking the weights connecting each neuron.\n",
    "\n",
    "If we just had 1 weight and we wanted to check 1000 possible values, that wouldn't be so bad.  But if we have 20 weights, that means checking $20^{1000}$ possible combinations.    Remember the curse of dimensionality?  That might take a while.  Indeed, far, far longer than the age of the Universe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Backpropagation\n",
    "\n",
    "However some clever techniques have evolved out of realizing that we can write an analytic formula for the *gradient* going backwards through the network, and use that to update our weights (and biases, of course).\n",
    "\n",
    "For example, how about just checking 3 points for each weight and see if we can at least figure out which way is \"down hill\"? That's a start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can rewrite $J$ as\n",
    "$$ J = \\sum\\frac{1}{2}\\left(y - f\\left( f(X W^{(1)}) W^{(2)} \\right) \\right)^2$$\n",
    "\n",
    "and then compute\n",
    "$$\\frac{\\partial J}{\\partial W}$$\n",
    "in order to determine the slope of the cost function for each weight.  This is the **gradient descent** method.  Your choice of cost function is important here; specifically you want it to be differentiable.\n",
    "\n",
    "**GTR: From Vanderbilt**\n",
    "\n",
    "We'll want $\\partial J/\\partial W^{(1)}$ and $\\partial J/\\partial W^{(2)}$ separately. This allows us to ***[backpropagate](https://en.wikipedia.org/wiki/Backpropagation)*** the error contributions along each neuron and to change the weights where they most need to be changed.  It is like each observation gets a vote on which way is \"down hill\".  We compute the vector sum to decide the ultimate down hill direction.\n",
    "\n",
    "Once we know the down hill direction from the derivative, we update the weights by subtracting a scalar (the *learning rate*) times that derivative from the original weights-- this is just gradient descent! This is obviously much faster than randomly sampling all the possible combinations of weights.  \n",
    "\n",
    "<font color='red'>Watch the following short video to understand more of the mathematics of **backpropagation (= \"backward propagation of errors\")**.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient Descent\n",
    "\n",
    "**GTR: This is updated in Classification3 for 2022.  Merge in here if desired.**\n",
    "\n",
    "That brings us to the topic of [Gradient Descent](https://en.wikipedia.org/wiki/Gradient_descent) which comes in for log loss because there is no analytic solution (can't write the equation for $\\theta$ as we have been).\n",
    "\n",
    "Throughout the couse we have been trying to determine model parameters, $\\theta$, that minimize either the regression error or the classification error when fitting our training data (and not overfitting!). \n",
    "\n",
    "Sometimes we have been able to write an analytic solution for $\\theta$.  In MCMC we semi-randomly sampled the multi-dimensional $\\theta$ space to find the best answer (and map the full parameter space along the way).  But what happens if you are stuck on top of a freezing cold mountain and you have no map and can't magically jump from place to place?  You start walking **down**.  That's the basic idea of gradient descent--take a look around you, figure out which way is sloping downward the most and go *that* way.\n",
    "\n",
    "We are going to determine the local gradient of the loss function with respect to $\\theta$ and go in the steepest direction, until the gradient is zero (and we have arrived at our destination)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Mathematically, we have \n",
    "\n",
    "$$\\nabla_{\\theta}{\\rm MSE}({\\mathbf \\theta}) = \\frac{2}{N}X^T(X\\theta - y)$$\n",
    "\n",
    "That gives the uphill direction, so we compute the next step as\n",
    "\n",
    "$$\\theta^{\\rm next step} = \\theta - \\eta\\nabla_{\\theta}{\\rm MSE}({\\mathbf \\theta}),$$\n",
    "\n",
    "where $\\eta$ is the \"learning rate\" and the rest are all matrices or vectors.\n",
    "\n",
    "Note that the initial values for $\\theta$ are chosen randomly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We'll want $\\partial J/\\partial W^{(1)}$ and $\\partial J/\\partial W^{(2)}$ separately.  This allows us to [*backpropagate*](https://en.wikipedia.org/wiki/Backpropagation) the error contributions along each neuron and to change the weights where they most need to be changed.  It is like each observation gets a vote on which way is \"down hill\".  We compute the vector sum to decide the ultimate down hill direction.\n",
    "\n",
    "Once we know the down hill direction from the derivative, we update the weights by subtracting a scalar times that derivative from the original weights.  That's obviously much faster than randomly sampling all the possible combinations of weights.  Once the weights are set, then you have your Neural Network classifier/regressor.\n",
    "\n",
    "![Ivezic Figure 9.17](https://www.astroml.org/_images/fig_neural_network_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Learning Rates\n",
    "\n",
    "The [learning rate](https://en.wikipedia.org/wiki/Learning_rate), which controls how big your steps \"down\" are.  If your step size is too small, it will take too long to converge.  If it is too big, you might miss the bottom completely (and possibly end up diverging from the solution).  \n",
    "\n",
    "\n",
    "![https://miro.medium.com/max/1400/0*GaO7X6j3coh3oNwf.png](https://miro.medium.com/max/1400/0*GaO7X6j3coh3oNwf.png)\n",
    "\n",
    "We also have to be careful that we don't end up in a local minimum instead of the global minimum.  (One of the nice things about the $l2$ cost function is that it is guaranteed to have just a single global minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Diverges because the sign of the gradient was opposite to what it just was?  Add figure showing this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Note that gradient descent is also useful for regression where too many training points (or too many features) to fit into memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here's an example from Geron where we apply gradient descent to a simple linear regression problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Run the next 4 cells\n",
    "#N points randomly drawn from a linear distribution\n",
    "N=100\n",
    "X = 2 * np.random.rand(N, 1)\n",
    "y = 4 + 3 * X + np.random.randn(N, 1)\n",
    "\n",
    "#Turn X into a matrix\n",
    "X_b = np.c_[np.ones((100, 1)), X]  # add x0 = 1 to each \n",
    "\n",
    "#Grid for plotting\n",
    "X_new = np.array([[0], [2]])\n",
    "X_new_b = np.c_[np.ones((2, 1)), X_new]  # add x0 = 1 to each instance\n",
    "\n",
    "X_b = np.c_[np.ones((100, 1)), X]  # add x0 = 1 to each instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "eta = 0.1  # learning rate\n",
    "n_iterations = 100\n",
    "theta = np.random.randn(2,1)  # random initialization\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    gradients = 2/N * X_b.T.dot(X_b.dot(theta) - y)\n",
    "    theta = theta - eta * gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "n_lines=10\n",
    "color_idx = np.linspace(0, 1, n_lines)\n",
    "#Helper function\n",
    "theta_path_bgd = []\n",
    "def plot_gradient_descent(theta, eta, theta_path=None):\n",
    "    m = len(X_b)\n",
    "    plt.plot(X, y, \"b.\")\n",
    "    n_iterations = 1000\n",
    "    for iteration in range(n_iterations):\n",
    "        if iteration < 10:\n",
    "            y_predict = X_new_b.dot(theta)\n",
    "            #style = \"b-\" if iteration > 0 else \"r--\"\n",
    "            #plt.plot(X_new, y_predict, style)\n",
    "            plt.plot(X_new, y_predict, color=plt.cm.cool(color_idx[iteration]))\n",
    "        gradients = 2/m * X_b.T.dot(X_b.dot(theta) - y)\n",
    "        theta = theta - eta * gradients\n",
    "        if theta_path is not None:\n",
    "            theta_path.append(theta)\n",
    "    plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "    plt.axis([0, 2, 0, 15])\n",
    "    plt.title(r\"$\\eta = {}$\".format(eta), fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "theta = np.random.randn(2,1)  # random initialization\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(131); plot_gradient_descent(theta, eta=0.02)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.subplot(132); plot_gradient_descent(theta, eta=0.1, theta_path=theta_path_bgd)\n",
    "plt.subplot(133); plot_gradient_descent(theta, eta=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "On the left our learning rate is too low; we'll eventually get to the solution, but it will take a long time.  On the right it is too high and we have completely missed the solution.  In the middle is just right.\n",
    "\n",
    "Try $\\eta = 0.3$ and $0.4$ to see if you can understand what is going on in the right panel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So, getting the learning rate right is important both for converging quickly and even doing so at all.\n",
    "\n",
    "[Geron11-8.png](attachment:Geron11-8.png)\n",
    "\n",
    "You also don't have to keep the learning rate fixed, but can instead do learning rate scheduling.  For example, see this [article](https://towardsdatascience.com/learning-rate-schedule-in-practice-an-example-with-keras-and-tensorflow-2-0-2f48b2888a0c).\n",
    "\n",
    "[Geron](../figures/Geron11-8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Scikit-Learn has both [unsupervised Neural Network](http://scikit-learn.org/stable/modules/neural_networks_unsupervised.html#neural-networks-unsupervised) and [supervised Neural Network](http://scikit-learn.org/stable/modules/neural_networks_supervised.html#neural-networks-supervised) examples. \n",
    "\n",
    "Let's try to use the multi-layer perceptron classifier on the California House Price dataset (using 75% of the data for training and 25% for testing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X = housing.data\n",
    "y = housing.target\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "Xtrain_scaled = preprocessing.scale(Xtrain)\n",
    "Xtest_scaled = preprocessing.scale(Xtest)\n",
    "Xscaled = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "clf = MLPRegressor(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5,2), random_state=1, max_iter=5000)\n",
    "clf.fit(Xtrain_scaled, ytrain)\n",
    "\n",
    "# Look at the weights\n",
    "print([coef.shape for coef in clf.coefs_])\n",
    "\n",
    "ypred = clf.predict(Xtest_scaled)\n",
    "#print ypred, ytest\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "plt.scatter(ytest,ypred)\n",
    "plt.xlabel(\"Actual Value [x$1000]\")\n",
    "plt.ylabel(\"Predicted Value [x$1000]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Of course, that only predicts the value for a fraction of the data set. <font color='red'>Again, we can use Scikit-Learn's [cross_val_predict](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html#sklearn.model_selection.cross_val_predict) to make predictions for the full data set.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "yCVpred = cross_val_predict(clf, Xscaled, y, cv=5) # Complete\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "plt.scatter(y,yCVpred)\n",
    "plt.xlabel(\"Actual Value [x$1000]\")\n",
    "plt.ylabel(\"Predicted Value [x$1000]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Just as with other model hyperparameters, we can use cross-validation to determine the optimal number of layers, neurons per layer, etc. But for now, let's talk about some guidelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Number of Layers\n",
    "\n",
    "Ivezic: \n",
    "\n",
    "> \"*For data that can be represented by a linear model, no layers are required (McCullagh & Nelder 1989).  A single layer network can approximate any continuous function.  Two layers can represent arbitrary decision boundaries for smooth functions (Lippmann 1987).  More layers can represent non-continuous or complex structure within the data.*\"  \n",
    "\n",
    "Think about why no layers are needed for linear regression.  We just connect our input to the output where the synapses are the weights (slopes) and the output neurons add the constant (intecept).\n",
    "\n",
    "So you might start with a single layer, then add more layers and use cross-validation to determine when you are overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Geron has a good example of what adding layers does.  Say you had to draw a whole forest, but you couldn't cut and paste anything.  That would be very tedious.  But if you could draw just one leaf and copy that to make a small branch, then scale up a small branch to a big branch and copy that, then attach the branches to a tree trunk and then make copies of the full tree, you wouldn't have to draw all that much.  **Each of the layers in a neural network handles  more and more detailed aspects of the problem.**\n",
    "\n",
    "For image recognition, you might need dozens of layers, but also a huge training set to populate those layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Number of Neurons\n",
    "\n",
    "The number of neurons in each layer is also a free parameter. \n",
    "\n",
    "- ***Typically choose somewhere between twice the number of input nodes and a number between the number of input and output nodes.***\n",
    "\n",
    "\n",
    "- If there are lots hidden layers (where \"lots\" is not clearly defined) then we call that a **deep neural network or [deep learning](https://en.wikipedia.org/wiki/Deep_learning)**. \n",
    "\n",
    "\n",
    "- Sometimes the number of neurons in each layer goes down.  But it can also be useful to have the same number in each layer so that there is only one hyperparameter (the number of neurons) and not one per layer.\n",
    "\n",
    "\n",
    "- In practice a reasonable approach is to simply **specify many more layers and neurons than you need and perform regularization**. This can be as simple as just stopping the training when the cross-validation error reaches a minimum, which appropriately (for once) is called **[early stopping](https://en.wikipedia.org/wiki/Early_stopping)**. Basically, you put your `fit` method into a loop and instantiate with `max_iter=1` and `warm_start=True`.  See Geron (page 141) for an example.\n",
    "\n",
    "\n",
    "While the number of neurons in the hidden layers are free parameters the number of input and output nodes are constrained by the data and the desired output.  For example, the MNIST digits data requires 784 input neurons (one for each pixel in the 28x28 images) and 10 output neurons (one for each class [digit]).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Activation Functions\n",
    "\n",
    "The **[Activation function](https://en.wikipedia.org/wiki/Activation_function)** controls how much \"signal\" it takes for a neuron to \"fire\".  The more signal, the more likely the neuron will fire. See https://mlfromscratch.com/activation-functions-explained/#/\n",
    "\n",
    "The cells below show different activation functions, using the same visualization as we used for loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Mathematical formulas for activation functions\n",
    "  \n",
    "def binary(raw_model_output):\n",
    "    return np.where(raw_model_output < 0, \n",
    "                    0, \n",
    "                    1)  \n",
    "\n",
    "def sigmoid(raw_model_output):\n",
    "    return 1.0 / (1 + np.exp(-raw_model_output))\n",
    "\n",
    "def ReLU(raw_model_output):\n",
    "    return np.where(raw_model_output < 0, \n",
    "                    0, \n",
    "                    raw_model_output)\n",
    "\n",
    "def LReLU(raw_model_output):\n",
    "    alpha=0.1\n",
    "    return np.where(raw_model_output < 0, \n",
    "                    alpha*raw_model_output, \n",
    "                    raw_model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Create a grid of values and plot\n",
    "grid = np.linspace(-3,3,1000)\n",
    "#plt.plot(grid, log_loss(grid), label='logistic')\n",
    "plt.plot(grid, binary(grid), \"k\", label='binary')\n",
    "plt.plot(grid, sigmoid(grid), \"b\", label='sigmoid')\n",
    "#plt.plot(grid, ReLU(grid), label='ReLU')\n",
    "#plt.plot(grid, LReLU(grid), label='LReLU')\n",
    "#plt.plot(grid, l2(grid), label='L2')\n",
    "#plt.plot(grid, l1(grid), label='L1')\n",
    "\n",
    "plt.fill_between([0,3], y1=-1, y2=3, \n",
    "                 color=\"b\", alpha=0.2)\n",
    "plt.fill_between([-3,0], y1=-1, y2=3, \n",
    "                 color=\"r\", alpha=0.2)\n",
    "plt.xlim([-3,3])\n",
    "plt.ylim([-1,3])\n",
    "plt.xlabel(\"z\",fontsize=12)\n",
    "plt.title(\"don't fire                 fire\",fontsize=12)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\"*On vs. Off*\" activation actually isn't quite true or what we want. The way your eyes work is that you need 1-10 photons to trigger a rod, but several rods must be triggered to send a signal to the brain. The sigmoid activation function captures the probabilistic nature of neuron firing. More importantly it is differentiable, so can be used for backpropagation.\n",
    "\n",
    "Another important aspect of non-linear activation functions is that they are what allow neural networks to solve non-linear problems.  If we used a strictly linear activation function, then we could only solve linear problems.  That is, you could fit a straight line, but not an exponential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If you wanted to make the activation function a parameter, here's how to find out what your options are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Different activation functions that are available\n",
    "[m for m in dir(keras.activations) if not m.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Vanishing and Exploding Gradients\n",
    "\n",
    "Neural network research suffered significant limitations and problems at the hands of the [vanishing and exploding gradients](https://en.wikipedia.org/wiki/Vanishing_gradient_problem) problem.  We won't go into detail there except to say that ***around 2010 there were suggestions for different activation functions that were published.***  \n",
    "\n",
    "- For example, the **[Rectified Linear Unit (ReLU) activation function](https://www.wikiwand.com/en/Rectifier_(neural_networks))** is another commonly used activation function as it solves the vanishing gradient problem (since the gradient is only 0 or 1).\n",
    "$${\\rm ReLU}(z) = max(0,z)$$\n",
    "\n",
    "\n",
    "- It isn't ideal both because the derivative is 0 for $z<0$ and it can end up producing dead nodes. However, it is fast and the resulting sparsity can be good (sort of like regularization).\n",
    "\n",
    "\n",
    "- A number of papers since 2015 describe various improvements, including the **Leaky ReLU**, the **exponential linear unit (ELU)**, and **scaled exponential linear unit (SELU)**.\n",
    "\n",
    "\n",
    "Note that the activation functions can be different in different layers.  For example, for regression, one typically doesn't use any activation function in the output layer as including one would restrict the range of possible outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Create a grid of values and plot\n",
    "grid = np.linspace(-3,3,1000)\n",
    "#plt.plot(grid, log_loss(grid), label='logistic')\n",
    "#plt.plot(grid, binary(grid), \"k\", label='binary')\n",
    "#plt.plot(grid, sigmoid(grid), \"b\", label='sigmoid')\n",
    "plt.plot(grid, ReLU(grid), \"b--\", label='ReLU')\n",
    "plt.plot(grid, LReLU(grid), \"orange\", label='LReLU')\n",
    "#plt.plot(grid, l2(grid), label='L2')\n",
    "#plt.plot(grid, l1(grid), label='L1')\n",
    "\n",
    "plt.fill_between([0,3], y1=-1, y2=3, \n",
    "                 color=\"b\", alpha=0.2)\n",
    "plt.fill_between([-3,0], y1=-1, y2=3, \n",
    "                 color=\"r\", alpha=0.2)\n",
    "plt.xlim([-3,3])\n",
    "plt.ylim([-1,3])\n",
    "plt.xlabel(\"z\",fontsize=12)\n",
    "plt.title(\"don't fire                       fire\",fontsize=12)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Some general guidance on activation functions:\n",
    "    \n",
    "* **Use sigmoid for output of binary classification (with binary cross entropy loss)**\n",
    "\n",
    "\n",
    "* **Use ReLU for layers other than output (at least to start with because it is faster)**\n",
    "\n",
    "\n",
    "* **Use softmax for output with more than 2 classes (with categorical cross entropy loss)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Regularization\n",
    "\n",
    "Just as we can use regularization for standard regression and classification tasks, so too can we with neural networks.  \n",
    "\n",
    "Not only can we apply the usual $L1$ (LASSO) or $L2$ (Ridge) regularization techniques, we can also use **dropout** which, as the name indicates, causes some neurons to be temporarily \"dropped out\" during training (usually by setting some probability for that to happen, typically 10-50%). After training, all of the neurons are used.\n",
    "\n",
    "*Geron* explains this in terms of a company needing to try to figure out how to adapt to a crucial employee being out sick for a period of time.  In the end, it can make the company stronger as more people (neurons) are able to handle certain parts of the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "One form of regularization is  \"early stopping\".  This will determine when there hasn't been any improvement in the validation set for `patience` epochs and stop the fitting.  It also uses the \"best\" weights and just the \"last\" weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Batch normalization\n",
    "\n",
    "Just as it is often necessary to normalize or standardize our features, sometimes it is helpful to do the same to the output of the hidden layers.  This is called **[batch normalization](https://en.wikipedia.org/wiki/Batch_normalization)** and is done before passing the data to the activation function.  It make the process more stable and can also make it faster.  We'll do an example next time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Faster Optimizers\n",
    "\n",
    "We aren't going to talk about optimizers, but it might be useful for you to have some options to feed into a search for the best parameter using cross validation.  For example **`['mse', 'adam', 'sgd', 'adagrad']`**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**GTR: Stop the notebook here and start another?  But leaving this for now.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we want to do anything more complicated, we'll need to use something other than Scikit-Learn.  Enter Keras and TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "[Keras](https://keras.io/) is a deep learning API.  Essentially it is Scikit-Learn for deep neural networks.\n",
    "\n",
    "Keras needs a computational backend to handle the heavy computation.  Three popular (open sources) deep learning libraries are [TensorFlow](https://www.tensorflow.org/), Microsoft Cognitive Toolkit, and [Theano](http://www.deeplearning.net/software/theano/).  TensorFlow now comes bundled with a version of Keras and that's what we'll use here (actually TensorFlow 2).  Another option is PyTorch.   Section 9.8 of Ivezic includes examples using both `keras` and `torch`.\n",
    "\n",
    "If you apply for a data-science job in industry knowing one of these tools might be the most useful thing for you to have learned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In short, for neural networks:\n",
    "\n",
    "> numpy -> tensorflow\n",
    "\n",
    "> sklearn -> keras\n",
    "\n",
    "In the same way that you can build a linear regression algorithm in numpy without using sklearn, you can build a neural network algorithm (not to mention linear regression) in tensorflow without using keras.  But just as sklearn makes our life easier, so too does keras.  Keras has Sequential and Functional APIs.  We will just use Sequential in our examples.\n",
    "\n",
    "Just as I'm teaching you about sklearn and not numpy, I have no intention of teaching you tensorflow, so this notebook should really be named keras.ipynb and not tensorflow.ipynb.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The following cells are from Geron, Chapter 10, see \n",
    "https://github.com/ageron/handson-ml2/blob/master/10_neural_nets_with_keras.ipynb\n",
    "\n",
    "I'll indicate below when I switch chapters.\n",
    "\n",
    "We'll start by introducing the Fashion MNIST data set, which is as common for learning about neural networks as the MNIST are for machine learning in general.  We can also use the MNIST data too.\n",
    "\n",
    "The next cells load the data, define test, trainging, and validation sets; normalize the data; display an example image; list the possible target values ($y$), and show a 4x10 grid of examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "print(X_train_full.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255.\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(X_train[0], cmap=\"binary\", origin='upper') #Origin controls right-side up\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Take a look at some of the other entries in the training data.  Also see what happens when you remove the `origin='upper'` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Let's make a list of class names that we can refer to.\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot 4x10 array of images from the Fashion MNIST database\n",
    "n_rows = 4\n",
    "n_cols = 10\n",
    "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\", origin='upper')\n",
    "        plt.axis('off')\n",
    "        plt.title(class_names[y_train[index]], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we'll build a \"simple\" neural network that classifies an unknown image (preprocessed to have the same image and color scale) into one of these 10 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session() #Make sure that we are starting a new model and not adding to an earlier one\n",
    "np.random.seed(42) #Set the numpy and tensorflow random seeds so that we all get the same answer\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential() #Instantiate a sequential model\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28])) #Define the input layer\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\")) #First hidden layer\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\")) #Second hidden layer\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\")) #Output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "[GTR: this notebook currently doesn't discuss activation functions until later.  Might need to fix that.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Need to define the input size/shape for the first layer.  The others know how to talk to each other.  The last layer sets the number of outputs.  Need softmax here because there are 10 categories.  If just one output or two, then a different activation function would be used."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#Same as above, just different syntax\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Let's see what we just built\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The number of parameters in each layer is one for each weight that connects each node of the layer to the previous layer, plus the number of neurons in the layer to account for the constant \"bias\" parameter (e.g., 784x300+300 = 235500).\n",
    "\n",
    "Note that \"Dense\" here means \"fully connected\".  That is, each node in one layer is connected to each node in the next layer.  This does't always have to be the case.  The layers can instead be \"Sparse\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can access (or set) the weights with `get_weights()` and `set_weights()` as follows.  Note that the initial weights are set randomly and the bias values are initially zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]\n",
    "weights, biases = hidden1.get_weights()\n",
    "#Weights set to random numbers to break degeneracy\n",
    "#Biases are set to 0\n",
    "print(weights.shape,weights,biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For neural networks we can't just fit the model after we instantiate it.  We need to compile first--specifying the loss function, the optimizer, and any desired metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#For binary classification instead do this\n",
    "#(and change the activation function of the output layer from \"softmax\" to \"sigmoid\"\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we can go ahead and fit the model with our training data.  The fit method will output a bunch of useful diagnostics that we'll save to `history` for plotting later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=25,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Comment on what is happening with loss, val_loss, and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Our metrics of interest were printed at each epoch (each pass through the neural network to update the weights), but it is easier to just look at a plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(12, 8))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.gca().set_xlabel(\"Epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As was the case for model training before, we want to make sure that we aren't overtraining, which would be indicated by the training loss diverging from the validation loss.  Note that, instead of creating a specific validation set, we can also pass `validation_split=0.1` as a parameter during the fitting step to split off 10% of the data for validation.\n",
    "\n",
    "Now we will `evaluate` the model using the test set to determine the expected level of error on unknown data.    The usual `predict` method then can be used to make predictions.  [GTR: I'm not sure the reason for this structure.  In regular ML we would `predict` on the test set and the compute metrics with the output values.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Evaluate the test set\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Predict values for first 3 test objects\n",
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new).round(2)\n",
    "print(y_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So, you can see that the output is a probability that the object belongs to each class (which has to sum to 1 across all the classes).  If we just want an \"answer\", we assign it to the class with the highest probability (done here with `predict_classes`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#y_pred = model.predict_classes(X_new) #Old way\n",
    "y_pred = np.argmax(model.predict(X_new), axis=-1) #New way\n",
    "print(y_pred)\n",
    "print(np.array(class_names)[y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Let's plot those and see if the predictions make sense.\n",
    "plt.figure(figsize=(7.2, 2.4))\n",
    "for index, image in enumerate(X_new):\n",
    "    plt.subplot(1, 3, index + 1)\n",
    "    plt.imshow(image, cmap=\"binary\", interpolation=\"nearest\", origin='upper')\n",
    "    plt.axis('off')\n",
    "    plt.title(class_names[y_test[index]], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "#save_fig('fashion_mnist_images_plot', tight_layout=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Note that after you fit your model, you can save it and reload it at some later time (which is good because some models might take hours to train!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Save model\n",
    "model.save(\"my_keras_model.h5\")\n",
    "\n",
    "#Reload model\n",
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's predict the values for 10 random objects.  Display them with their actual labels first, then predict and display the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "idx10 = np.random.choice(np.arange(len(y_test)), size=10, replace=False)\n",
    "X_new = X_test[idx10]\n",
    "#y_pred = model.predict_classes(X_new)\n",
    "y_pred = np.argmax(model.predict(X_new), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Correct answers (y_test)\n",
    "plt.figure(figsize=(15, 5))\n",
    "for index, image in enumerate(X_new):\n",
    "    plt.subplot(1, 10, index + 1)\n",
    "    plt.imshow(image, cmap=\"binary\", interpolation=\"nearest\", origin='upper')\n",
    "    plt.axis('off')\n",
    "    plt.title(class_names[y_test[idx10[index]]], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Predicted answers (y_pred)\n",
    "plt.figure(figsize=(15, 5))\n",
    "for index, image in enumerate(X_new):\n",
    "    plt.subplot(1, 10, index + 1)\n",
    "    plt.imshow(image, cmap=\"binary\", interpolation=\"nearest\", origin='upper')\n",
    "    plt.axis('off')\n",
    "    plt.title(class_names[y_pred[index]], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here's a regression example instead of classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Activation Functions\n",
    "\n",
    "[Activation function](https://en.wikipedia.org/wiki/Activation_function) control how much \"signal\" it takes for a neuron to \"fire\".  The more signal, the more likely the neuron will fire.\n",
    "\n",
    "See\n",
    "https://mlfromscratch.com/activation-functions-explained/#/\n",
    "\n",
    "The cells below show different activation functions, using the same visualization as we used for loss functions.  It is important to understand the differences between them and when you can and cannot use certain activation functions.  For example, the activation function of your output layer depends on your output (specifically regression, binary classification, or multi-class classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Mathematical formulas for activation functions\n",
    "\n",
    "def binary(raw_model_output):\n",
    "   return np.where(raw_model_output < 0, 0, 1)  \n",
    "\n",
    "def sigmoid(raw_model_output):\n",
    "   return 1.0/(1+np.exp(-raw_model_output))\n",
    "\n",
    "def ReLU(raw_model_output):\n",
    "   return np.where(raw_model_output < 0, 0, raw_model_output)\n",
    "\n",
    "def LReLU(raw_model_output):\n",
    "   alpha=0.1\n",
    "   return np.where(raw_model_output < 0, alpha*raw_model_output, raw_model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a grid of values and plot\n",
    "grid = np.linspace(-3,3,1000)\n",
    "#plt.plot(grid, log_loss(grid), label='logistic')\n",
    "plt.plot(grid, binary(grid), \"k\", label='binary')\n",
    "plt.plot(grid, sigmoid(grid), \"b\", label='sigmoid')\n",
    "#plt.plot(grid, ReLU(grid), label='ReLU')\n",
    "#plt.plot(grid, LReLU(grid), label='LReLU')\n",
    "#plt.plot(grid, l2(grid), label='l2')\n",
    "#plt.plot(grid, l1(grid), label='l1')\n",
    "\n",
    "plt.fill_between([0,3],-1,3,\"b\",alpha=0.4)\n",
    "plt.fill_between([-3,0],-1,3,\"r\",alpha=0.5)\n",
    "plt.xlim([-3,3])\n",
    "plt.ylim([-1,3])\n",
    "plt.xlabel(\"z\",fontsize=12)\n",
    "#plt.ylabel(\"probability\",fontsize=12)\n",
    "plt.title(\"don't fire                 fire\",fontsize=12)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Until the paper describing backpropagation, a step (binary) function was used for activation: that is either *on* or *off*, which makes sense as neurons either fire or they don't.  However, the step function doesn't have gradients, so backpropagation won't work with them.  \n",
    "\n",
    "Moreover on vs. off actually isn't quite true.  The way your eyes work is that you need 1-10 photons to trigger a rod, but several rods must be triggered to send a signal to the brain.  The sigmoid activation function captures the probabilistic nature of neuron firing.  More importantly it is differentiable, so can be used for backpropagation.\n",
    "\n",
    "Another important aspect of non-linear activation function is that they are what allow neural networks to solve non-linear problems.  If we used a strictly linear activation function, then we could only solve linear problems.  That is, you could fit a straight line, but not an exponential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Vanishing and Exploding Gradients\n",
    "\n",
    "However, neural networks suffered their 2nd death at the hands of the [vanishing and exploding gradients](https://en.wikipedia.org/wiki/Vanishing_gradient_problem) problem.  We won't go into detail there except to say that life #3 began around 2010 when suggestions for different activation functions were published.  \n",
    "\n",
    "For example, the Rectified Linear Unit (ReLU) activation function is another commonly used activation function as it solves the vanishing gradient problem (since the gradient is only 0 or 1).\n",
    "\n",
    "$${\\rm ReLU}(z) = max(0,z)$$\n",
    "\n",
    "It isn't ideal both because the derivative is 0 for $z<0$ and it can end up producing dead nodes.  However, it is fast and the resulting sparsity can be good (sort of like regularization).\n",
    "\n",
    "A number of papers since 2015 describe various improvements, including the Leaky RELU, the exponential linear unit (ELU) and scaled exponential linear unit (SELU).\n",
    "\n",
    "Note that the activation functions can be different in different layers.  For example, for regression, one typically doesn't use any activation function in the output layer as including one would restriction the range of possible outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a grid of values and plot\n",
    "grid = np.linspace(-3,3,1000)\n",
    "#plt.plot(grid, log_loss(grid), label='logistic')\n",
    "#plt.plot(grid, binary(grid), \"k\", label='binary')\n",
    "#plt.plot(grid, sigmoid(grid), \"b\", label='sigmoid')\n",
    "plt.plot(grid, ReLU(grid), \"b--\", label='ReLU')\n",
    "plt.plot(grid, LReLU(grid), \"orange\", label='LReLU')\n",
    "#plt.plot(grid, l2(grid), label='l2')\n",
    "#plt.plot(grid, l1(grid), label='l1')\n",
    "\n",
    "plt.fill_between([0,3],-1,3,\"b\",alpha=0.4)\n",
    "plt.fill_between([-3,0],-1,3,\"r\",alpha=0.5)\n",
    "plt.xlim([-3,3])\n",
    "plt.ylim([-1,3])\n",
    "plt.xlabel(\"z\",fontsize=12)\n",
    "#plt.ylabel(\"probability\",fontsize=12)\n",
    "plt.title(\"don't fire                 fire\",fontsize=12)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Some general guidance on activation functions (more on this later):\n",
    "    \n",
    "* Use sigmoid for output of binary classification (with binary cross entropy loss)\n",
    "* Use ReLU for layers other than output (at least to start with because it is faster)\n",
    "* Use softmax for output with more than 2 classes (with categorical cross entropy loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If you wanted to make the activation function a parameter, here's how to find out what your options are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Different activation functions that are available\n",
    "[m for m in dir(keras.activations) if not m.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Regularization\n",
    "\n",
    "Just as we can use regularization for standard regression and classification task, so too can we with neural networks.  \n",
    "\n",
    "Not only can we apply the usual $l1$ or $l2$ regularization techniques, but we can also use *dropout* which, as the name indicates, causes some neurons to be temporarily \"dropped out\" during training (usually by setting some probability for that to happen, typically 10-50%).  After training, all of the neurons are used.\n",
    "\n",
    "Geron explains this as a company needing to try to figure out how to adapt to a crucial employee being out sick for a period of time.  In the end, it can make the company stronger as more people (neurons) are able to handle certain parts of the process.\n",
    "\n",
    "We'll do an example of this next time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "One form of regularization is  \"early stopping\".  This will determine when there hasn't been any improvement in the validation set for `patience` epochs and stop the fitting.  It also uses the \"best\" weights and just the \"last\" weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                  restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[early_stopping_cb])\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Note that we told it that it could run for as many as 100 epochs if it wanted to, but it stopped after 74.\n",
    "\n",
    "Now we can plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(12, 8))\n",
    "plt.grid(True)\n",
    "#plt.gca().set_ylim(0, 1)\n",
    "plt.gca().set_xlabel(\"Epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here's an example of how to do regularization with [dropout](https://en.wikipedia.org/wiki/Dilution_(neural_networks)).\n",
    "\n",
    "![DropoutDiagram](https://miro.medium.com/max/1400/1*tvcv2PT3cBAmUtZzQTmjeQ.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Back to the fashion MNIST data\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Dropout example\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dropout(rate=0.2), #20% chance of neuron stuck in off position\n",
    "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Just as it is often necessary to normalize or standardize our features, sometimes it is helpful to do the same to the output of the hidden layers.  This is called [batch normalization](https://en.wikipedia.org/wiki/Batch_normalization) and is done before passing the data to the activation function.  It make the process more stable and can also make it faster. \n",
    "\n",
    "Here's an example using batch normalization.\n",
    "\n",
    "[GTR: Not sure where to put this.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In some cases you might want to do the batch normalization before applying the activation function.  Here we also turn off the bias parameter because it ends up not being needed and just wastes a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(100, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We have a number of hyperparameters that can be tuned when building the architecture of our neural network (such as the number of hidden layers and the number of neurons in those layers).  But also the activation functions, learning rates, etc.\n",
    "\n",
    "Just as with other model hyperparameters, we can use cross-validation to determine the optimal number of layers, neurons per layer, etc.  We'll do that in detail later.  For now, let's talk about some guidelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Number of Layers\n",
    "\n",
    "Ivezic: \n",
    "> \"For data that can be represented by a linear model, no layers are required (McCullagh & Nelder 1989).  A single layer network can approximate any continuous function.  Two layers can represent arbitrary decision boundaries for smooth functions (Lippmann 1987).  More layers can represent non-continuous or complex structure within the data.\"  \n",
    "\n",
    "\n",
    "Think about why no layers are needed for linear regression.  We just connect our input to output where they synapses are the weights (slopes) and the output neurons add the constant (intecept).\n",
    "\n",
    "So you might start with a single layer, then add more layers and use cross-validation to determine when you are overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Geron has a good example of what adding layers does.  Say you had to draw a whole forest, but you couldn't cut and paste anything.  That would be very tedious.  But if you could draw just one leaf and copy that to make a small branch, then scale up a small branch to a big branch and copy that, then attach the branches to a tree trunk and then make copies of the full tree, you wouldn't have to draw all that much.  Each of the layers in a neural network handles  more and more detailed aspects of the problem.  We saw this in the opening pre-lecture experiments.\n",
    "\n",
    "For image recognition, you might need dozens of layers, but also a huge training set to populate those layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Number of Neurons\n",
    "\n",
    "The number of neurons in each layer is also a free parameter.  Typically choose somewhere between twice the number of input nodes and a number between the number of input and output nodes.\n",
    "\n",
    "If there are lots of hidden layers (where \"lots\" is not clearly defined) then we call that a deep neural network or [deep learning](https://en.wikipedia.org/wiki/Deep_learning).  More on that later.\n",
    "\n",
    "\n",
    "Sometimes the number of neurons in each layer goes down.  But it can also be useful to have the same number in each layer so that there is only one hyperparameter (the number of neurons) and not one per layer.\n",
    "\n",
    "In practice a reasonable approach is to simply specify many more layers and neurons than you need and perform regularization.  This can be as simple as just stopping the training when the cross-validation error reaches a minimum, which appropriately (for once) is called [early stopping](https://en.wikipedia.org/wiki/Early_stopping).  Basically, you put your `fit` method into a loop and instantiate with `max_iter=1` and `warm_start=True`.  See Geron (page 141) for an example.  Indeed the examples from the start of class where we had to stop the process is a good illustration of this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "While the number of neurons in the hidden layers are free parameters the number of input and output nodes are constrained by the data and the desired output.  For example, the MNIST digits data requires 784 input neurons (one for each pixel in the 28x28 images) and 10 output neurons (one for each class [digit]).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Faster Optimizers\n",
    "\n",
    "We aren't going to talk about optimizers, but it might be useful for you to have some options to feed into a search for the best parameter using cross validation.  For example `['mse', 'adam', 'sgd', 'adagrad']`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now let's use cross validation to determine the best options.  Here we have so many that we'll use [RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) instead of `GridSearchCV`.\n",
    "\n",
    "First we need to do some preprocessing to get sklearn and keras to talk nicely to each other.\n",
    "\n",
    "Start by building the model in a way that the hyperparameters are themselves parameters, then wrap that model in a way that we can use it within sklearn.\n",
    "\n",
    "See\n",
    "https://github.com/ageron/handson-ml2/blob/master/10_neural_nets_with_keras.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=10, learning_rate=3e-3, input_shape=[28,28]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=input_shape))\n",
    "    for layer in range(n_hidden): #Because the number of hidden layers is a parameter\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(10, activation=\"softmax\")) #Output layer\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "keras_class = keras.wrappers.scikit_learn.KerasClassifier(build_model)\n",
    "#Note that there is also a KerasRegressor for regression problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`keras_class` can now be used with in sklearn in the same way as any other classifier.  For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    #\"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_hidden\": (0, 1),\n",
    "    #\"n_neurons\": np.arange(1, 30), #This would take too long for class!\n",
    "    \"n_neurons\": (5,10),\n",
    "    #\"learning_rate\": reciprocal(3e-4, 3e-2) #Not quite sure what this does, but it makes it take forever!\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_class, param_distribs, n_iter=10, cv=3, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We'll try this on the MNIST digits data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255.\n",
    "X_new = X_test[:10]\n",
    "y_new = y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(X_train[0], cmap=\"binary\", origin=\"upper\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Note that we are doing 3-fold cross validation, so the validation set isn't being used for training, just for early stopping."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "####Don't run this during class!  It will take too long!####\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100, \\\n",
    "                  validation_data=(X_valid,y_valid),\\\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(rnd_search_cv.best_params_)\n",
    "print(rnd_search_cv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "[m for m in dir(keras.layers) if \"relu\" in m.lower()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Advanced Topics in Neural Networks with Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Recent interest in neural networks surged in 2012 when a team using a deep [convolutional neural network (CNN)](https://en.wikipedia.org/wiki/Convolutional_neural_network) acheived record results classifying objects in the [ImageNet](http://image-net.org/) data set.\n",
    "\n",
    "The idea behind CNNs is inspired by human visual perception.  Each neuron in your visual cortex doesn't \"see\" all of what your eye can see at once and some neuron are more sensitive to one pattern over another (e.g., horizontal lines vs. vertical lines).  \n",
    "\n",
    "Moreover, the simplest deeply connected neural networks would choke on \"real\" data which has far more than 28x28 pixels and would require following tens of millions of connections.  So we use a combination of \"convolution\" and \"pooling\" to reduce the dimensionality of the data first.\n",
    "\n",
    "![Ivezic Figure 9.19](https://www.astroml.org/_images/fig_cnn_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convolutional Layers\n",
    "\n",
    "In a convolutional layer, each neuron is not connected to each neuron in the previous layer, but only those that are within its \"field of view\" as defined by a kernel (filter).  We slide the kernel over the input layer and the value in the next layer depends only on those pixels.\n",
    "\n",
    "![Convolutional Layer](https://miro.medium.com/max/1400/1*wLlXFtWI--7knyQT2wlhMg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here's another perspective that helps to visualize going from one layer to the next.\n",
    "\n",
    "![Convolution example](https://developer.apple.com/library/content/documentation/Performance/Conceptual/vImage/Art/kernel_convolution.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "[Geron14-3.png](attachment:Geron14-3.png)\n",
    "\n",
    "[Geron14-4.png](attachment:Geron14-4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Choosing a filter (kernel) with a certain pattern can help recognize certain types of features (like horizontal aor vertical lines).\n",
    "\n",
    "![vertical filter](https://miro.medium.com/max/1338/1*7IEbBib7Yc7qST5IGQoYXA.jpeg)\n",
    "\n",
    "![horizontal filter](https://miro.medium.com/max/1238/1*PSSAaH2pZbl5bK3Ef_zk4A.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "[Geron14-5.png](attachment:Geron14-5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It is common to follow the convolutional layer by a so-called \"pooling layer\", essentially to reduce the amount of data that needs to be processed.  The full architecture of a CNN might look something like this:\n",
    "![CNN Example](https://www.researchgate.net/profile/Xian_Wei2/publication/331986652/figure/fig1/AS:740547106988032@1553571597647/The-classic-structure-of-CNN-It-consists-of-two-modules-Feature-extraction-module-and.ppm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Where the pooling layers are reducing the number of pixels by averaging, summing, taking the max, etc.:\n",
    "\n",
    "![Pooling example](https://miro.medium.com/max/1000/1*ydNsGDxMldAiq7b96GDQwg.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "[Geron14-8.png](attachment:Geron14-8.png)\n",
    "\n",
    "[Geron14-9.png](attachment:Geron14-9.png)\n",
    "\n",
    "[Geron14-11.png](attachment:Geron14-11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "When you are done, the output gets feed into a regular, fully connected neural network which outputs the predictions.\n",
    "\n",
    "This is clearly much more sophisticated than our basic perceptron. \"Deep\" networks consist of tens of layers with thousands of neurons. These large networks have become usable thanks to two breakthroughs: the use of sparse layers and the power of graphics processing units (GPUs).\n",
    "\n",
    "The sparse layers or convolutional layers in a deep network contain a large number of hidden nodes but very few synapses. The sparseness arises from the relatively small size of a typical convolution kernel (15x15 is a large kernel), so a hidden node representing one output of the convolution is connected to only a few input nodes. Compare this the our previous perceptron, in which every hidden node was connected to every input node.\n",
    "\n",
    "Even though the total number of connections is greatly reduced in the sparse layers, the total number of nodes and connections in a modern deep network is still enormous. Luckily, training these networks turns out to be a great task for GPU acceleration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For further study, there are lots of resources for CNNs online.  For example, see\n",
    "https://medium.com/analytics-vidhya/convolutional-neural-networks-cnn-explained-step-by-step-69137a54e5e7\n",
    "    \n",
    "Now let's see a worked example of a CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "GTR: Output of convolution is a \"feature map\".  Number of weights needed (which are computed from backpropagation is just the kernel size times the number of layers.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### CNN Example using Fashion MNIST\n",
    "\n",
    "See https://github.com/ageron/handson-ml2/blob/master/14_deep_computer_vision_with_cnns.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session() #Make sure that we are starting a new model and not adding to an earlier one\n",
    "np.random.seed(42) #Set the numpy and tensorflow random seeds so that we all get the same answer\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
    "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]\n",
    "\n",
    "X_mean = X_train.mean(axis=0, keepdims=True)\n",
    "X_std = X_train.std(axis=0, keepdims=True) + 1e-7\n",
    "X_train = (X_train - X_mean) / X_std\n",
    "X_valid = (X_valid - X_mean) / X_std\n",
    "X_test = (X_test - X_mean) / X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Need to reshape for CNN\n",
    "X_train = X_train[:, :, :, np.newaxis]\n",
    "X_valid = X_valid[:,  :, :, np.newaxis]\n",
    "X_test = X_test[:, :, :, np.newaxis]\n",
    "\n",
    "print(len(X_train))\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=[28, 28, 1]),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=7, activation='relu', padding='same'),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    keras.layers.Conv2D(128, 3, activation='relu', padding='same'),\n",
    "    keras.layers.Conv2D(128, 3, activation='relu', padding='same'),  \n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    keras.layers.Conv2D(256, 3, activation='relu', padding='same'),\n",
    "    keras.layers.Conv2D(256, 3, activation='relu', padding='same'),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(units=128, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=64, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=10, activation='softmax'),\n",
    "])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "\"same\" is with zero padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "####Do NOT run during class.  It will take too long!####\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now let's see how well this model does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X_new = X_test[:10] # to represent \"new\" images\n",
    "print(X_new.shape)\n",
    "\n",
    "y_pred = model.predict(X_new)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Use the `history` output to see the improvement in performance with each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "  \n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "accuracy = history_dict['accuracy']\n",
    "val_accuracy = history_dict['val_accuracy']\n",
    "  \n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "#\n",
    "# Plot the model accuracy vs Epochs\n",
    "#\n",
    "ax[0].plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "ax[0].plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "ax[0].set_title('Training & Validation Accuracy', fontsize=16)\n",
    "ax[0].set_xlabel('Epochs', fontsize=16)\n",
    "ax[0].set_ylabel('Accuracy', fontsize=16)\n",
    "ax[0].legend()\n",
    "#\n",
    "# Plot the loss vs Epochs\n",
    "#\n",
    "ax[1].plot(epochs, loss_values, 'bo', label='Training loss') \n",
    "ax[1].plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "ax[1].set_title('Training & Validation Loss', fontsize=16)\n",
    "ax[1].set_xlabel('Epochs', fontsize=16)\n",
    "ax[1].set_ylabel('Loss', fontsize=16)\n",
    "ax[1].legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "With image data one of the cool things that we can do is to visualize what the kernel in a given convolutional layer is actually doing.\n",
    "\n",
    "[GTR: However, I can't remember where I got this from and I can't get the last cell to work because I don't have the code for the \"convolution\" function.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "conv1 = model.layers[0]\n",
    "weights1 = conv1.get_weights()\n",
    "len(weights1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "kernels1 = weights1[0]\n",
    "kernels1.shape\n",
    "\n",
    "kernels1_1 = kernels1[:,:,0,0]\n",
    "kernels1_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(kernels1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "test_image = X_test[0, :, :, 0]\n",
    "plt.imshow(test_image, origin='upper')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "filtered_image = convolution(test_image, kernel1_1)\n",
    "plt.imshow(filtered_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "####Need sdss_images_1000.npy for this to work####\n",
    "\n",
    "#Ivezic v2, Figure 9.20, edits by GTR\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "if \"setup_text_plots\" not in globals():\n",
    "    from astroML.plotting import setup_text_plots\n",
    "setup_text_plots(fontsize=8, usetex=True)\n",
    "plt.rcParams['axes.xmargin'] = 0.05\n",
    "plt.rcParams['axes.ymargin'] = 0.05\n",
    "\n",
    "\n",
    "def read_savefile(filename):\n",
    "    '''Read npy save file containing images or labels of galaxies'''\n",
    "    return np.load(filename)\n",
    "\n",
    "\n",
    "def CNN(img_channels, img_rows, img_cols, verbose=False):\n",
    "    '''Define CNN model for Nair and Abraham data'''\n",
    "\n",
    "    # some hyperparamters you can chage\n",
    "    dropoutpar = 0.5\n",
    "    nb_dense = 64\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, 6, 6, border_mode='same',\n",
    "                            input_shape=(img_rows, img_cols, img_channels)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Convolution2D(64, 5, 5, border_mode='same'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Convolution2D(64, 5, 5, border_mode='same'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Convolution2D(128, 2, 2, border_mode='same'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Convolution2D(128, 3, 3, border_mode='same'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(nb_dense, activation='relu'))\n",
    "    model.add(Dropout(dropoutpar))\n",
    "    model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "    print(\"Compilation...\")\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    print(\"... done!\")\n",
    "    if verbose is True:\n",
    "        print(\"Model Summary\")\n",
    "        print(\"===================\")\n",
    "        model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_CNN(X, Y, ntrain, nval, output=\"test\", verbose=False):\n",
    "    '''Train the CNN given a dataset and output model and weights'''\n",
    "\n",
    "    # train params - hardcoded for simplicity\n",
    "    batch_size = 30\n",
    "    nb_epoch = 50\n",
    "    data_augmentation = True  # if True the data will be augmented at every iteration\n",
    "\n",
    "    ind = random.sample(range(0, ntrain+nval-1), ntrain+nval-1)\n",
    "    X_train = X[ind[0:ntrain], :, :, :]\n",
    "    X_val = X[ind[ntrain:ntrain+nval], :, :, :]\n",
    "    Y_train = Y[ind[0:ntrain]]\n",
    "    Y_val = Y[ind[ntrain:ntrain+nval]]\n",
    "\n",
    "    # input image dimensions\n",
    "    img_rows, img_cols = X_train.shape[1:3]\n",
    "    img_channels = 3\n",
    "\n",
    "    # Right shape for X\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols,\n",
    "                              img_channels)\n",
    "    X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, img_channels)\n",
    "\n",
    "    # Avoid more iterations once convergence\n",
    "    patience_par = 10\n",
    "    earlystopping = EarlyStopping(monitor='val_loss', patience=patience_par,\n",
    "                                  verbose=0, mode='auto' )\n",
    "    modelcheckpoint = ModelCheckpoint(output+\"_best.hd5\", monitor='val_loss',\n",
    "                                      verbose=0, save_best_only=True)\n",
    "\n",
    "    # Define CNN\n",
    "    model = CNN(img_channels, img_rows, img_cols, verbose=True)\n",
    "\n",
    "    if not data_augmentation:\n",
    "        print('Not using data augmentation.')\n",
    "        history = model.fit(X_train, Y_train,\n",
    "                            batch_size=batch_size,\n",
    "                            nb_epoch=nb_epoch,\n",
    "                            validation_data=(X_val, Y_val),\n",
    "                            shuffle=True, verbose=verbose,\n",
    "                            callbacks=[earlystopping, modelcheckpoint])\n",
    "    else:\n",
    "        print('Using real-time data augmentation.')\n",
    "        # this will do preprocessing and realtime data augmentation\n",
    "        datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,\n",
    "            samplewise_center=False,\n",
    "            featurewise_std_normalization=False,\n",
    "            samplewise_std_normalization=False,\n",
    "            zca_whitening=False,\n",
    "            rotation_range=45,\n",
    "            width_shift_range=0.05,\n",
    "            height_shift_range=0.05,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True,\n",
    "            zoom_range=[0.75, 1.3])\n",
    "\n",
    "        datagen.fit(X_train)\n",
    "\n",
    "        history = model.fit_generator(\n",
    "            datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
    "            samples_per_epoch=X_train.shape[0],\n",
    "            nb_epoch=nb_epoch,\n",
    "            validation_data=(X_val, Y_val),\n",
    "            callbacks=[earlystopping, modelcheckpoint])\n",
    "\n",
    "    print(\"Saving model...\")\n",
    "    # save weights\n",
    "    model.save_weights(output+\".weights\", overwrite=True)\n",
    "\n",
    "\n",
    "def apply_CNN(X, model_name):\n",
    "    '''Apply a CNN to a data set'''\n",
    "    # input image dimensions\n",
    "    img_rows, img_cols = X.shape[1:3]\n",
    "    img_channels = 3\n",
    "    X = X.reshape(X.shape[0], img_rows, img_cols, img_channels)\n",
    "\n",
    "    # load model & predict\n",
    "    print(\"Loading weights\", model_name)\n",
    "\n",
    "    model = CNN(img_channels, img_rows, img_cols)\n",
    "    model.load_weights(model_name+\".weights\")\n",
    "    Y_pred = model.predict_proba(X)\n",
    "\n",
    "    return Y_pred\n",
    "\n",
    "\n",
    "def add_titlebox(ax, text):\n",
    "    '''Add an embedded title into figure panel'''\n",
    "    ax.text(.1, .85, text,\n",
    "            horizontalalignment='left',\n",
    "            transform=ax.transAxes,\n",
    "            bbox=dict(facecolor='white', edgecolor='none', alpha=0.8))\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_CNN_performance(pred, labels):\n",
    "    '''Plot ROC curve and sample galaxies'''\n",
    "\n",
    "    fig = plt.figure(figsize=(6, 3))\n",
    "    fig.subplots_adjust(wspace=0.1, hspace=0.1,\n",
    "                        left=0.1, right=0.95,\n",
    "                        bottom=0.15, top=0.9)\n",
    "\n",
    "    # define shape of figure\n",
    "    gridsize = (2, 4)\n",
    "    ax1 = plt.subplot2grid(gridsize, (0, 0), colspan=2, rowspan=2)\n",
    "    ax2 = plt.subplot2grid(gridsize, (0, 2))\n",
    "    ax3 = plt.subplot2grid(gridsize, (0, 3))\n",
    "    ax4 = plt.subplot2grid(gridsize, (1, 2))\n",
    "    ax5 = plt.subplot2grid(gridsize, (1, 3))\n",
    "\n",
    "    # plot ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(labels, pred)\n",
    "\n",
    "    ax1.plot(fpr, tpr, color='black')\n",
    "    ax1.set_xlabel(r'False Positive Rate')\n",
    "    ax1.set_ylabel(r'True Positive Rate')\n",
    "\n",
    "    # array of objects (good E, good S, bad E, bad S)\n",
    "    goodE = np.where((pred[:, 0] < 0.5) & (labels == 0))\n",
    "    goodS = np.where((pred[:, 0] > 0.5) & (labels == 1))\n",
    "    badE = np.where((pred[:, 0] < 0.5) & (labels == 1))\n",
    "    badS = np.where((pred[:, 0] > 0.5) & (labels == 0))\n",
    "\n",
    "    ax2.imshow(D[pred_index + goodE[0][1]])\n",
    "    add_titlebox(ax2, \"Correct E\")\n",
    "    ax2.axis('off')\n",
    "\n",
    "    ax3.imshow(D[pred_index + goodS[0][4]])\n",
    "    add_titlebox(ax3, \"Correct Spiral\")\n",
    "    ax3.axis('off')\n",
    "\n",
    "    ax4.imshow(D[pred_index + badE[0][1]])\n",
    "    add_titlebox(ax4, \"Incorrect E\")\n",
    "    ax4.axis('off')\n",
    "\n",
    "    ax5.imshow(D[pred_index + badS[0][3]])\n",
    "    add_titlebox(ax5, \"Incorrect Spiral\")\n",
    "    ax5.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "n_objects = 500\n",
    "save_files = \"./SDSS{}\".format(n_objects)\n",
    "\n",
    "# Read SDSS images and labels\n",
    "D = read_savefile(\"sdss_images_1000.npy\")[0:n_objects]\n",
    "Y = read_savefile(\"sdss_labels_1000.npy\")[0:n_objects]\n",
    "\n",
    "# Train network and output to disk (keep 10% of data for test set)\n",
    "ntrain = D.shape[0] * 8 // 10.\n",
    "nval = D.shape[0] // 10\n",
    "npred = D.shape[0] - (ntrain + nval)  # test sample size;\n",
    "pred_index = ntrain + nval            # test sample start index;\n",
    "\n",
    "# Normalize images\n",
    "mu = np.amax(D, axis=(1, 2))\n",
    "for i in range(0, mu.shape[0]):\n",
    "    D[i, :, :, 0] = D[i, :, :, 0] / mu[i, 0]\n",
    "    D[i, :, :, 1] = D[i, :, :, 1] / mu[i, 1]\n",
    "    D[i, :, :, 2] = D[i, :, :, 2] / mu[i, 2]\n",
    "\n",
    "# change order so that we do not use always the same objects to train/test\n",
    "D, Y, = shuffle(D, Y, random_state=0)\n",
    "\n",
    "my_file = Path(save_files + \".weights\")\n",
    "if my_file.is_file():\n",
    "    Y_pred = apply_CNN(D[pred_index:pred_index + npred, :, :, :], save_files)\n",
    "    Y_test=Y[pred_index:pred_index + npred]\n",
    "else:\n",
    "    print(\"Training Model\")\n",
    "    print(\"====================\")\n",
    "    model_name = train_CNN(D, Y, ntrain, nval, output=save_files)\n",
    "    Y_pred = apply_CNN(D[pred_index:pred_index + npred, :, :, :], save_files)\n",
    "    Y_test = Y[pred_index:pred_index + npred]\n",
    "\n",
    "Y_pred_class = Y_pred * 0\n",
    "Y_pred_class[Y_pred > 0.5] = 1\n",
    "print(\"Global Accuracy:\", accuracy_score(Y_test, Y_pred_class))\n",
    "\n",
    "\n",
    "plot_CNN_performance(Y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Autoencoders\n",
    "\n",
    "Autoencoders are neural networks that copy their input to their output, but after passing the data through a bottleneck.  For example if there are 28x28 = 784 inputs, there will also be 784 outputs, but there will be one or more (odd, but symmetric) hidden layers with fewer neuron than that.\n",
    "\n",
    "For example see \n",
    "\n",
    "![autoencoder structure](https://miro.medium.com/max/1400/1*44eDEuZBEsmG_TCAKRI3Kw@2x.png)\n",
    "\n",
    "from\n",
    "https://towardsdatascience.com/applied-deep-learning-part-3-autoencoders-1c083af4d798"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "So, distill our MNIST digits down to the three most important pixels.  Or perhaps the three most important line segments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can think of this as doing PCA with a neural network -- breaking our data down into the only the most important features that we actually *need* (finding the intrinsic dimensionality).   In fact, if the network uses only linear (or no) activation functions and $l2$ cost function, then we have exactly PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How might this be useful?  Well, for example we can use it to reconstruct MNIST digits that have had noise added to them:\n",
    "\n",
    "![autoencoder example](https://miro.medium.com/max/1400/1*SxwRp9i23OM0Up4sEze1QQ@2x.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Autoencoder Example\n",
    "\n",
    "Let's build a stacked Autoencoder with 3 hidden layers and 1 output layer (i.e., 2 stacked Autoencoders) and run it on the fashion MNIST data set.\n",
    "\n",
    "See\n",
    "https://github.com/ageron/handson-ml2/blob/master/17_autoencoders_and_gans.ipynb\n",
    "\n",
    "Specifically, we are going to build this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "[Geron17-3autoencoder.png](attachment:Geron17-3autoencoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full.astype(np.float32) / 255\n",
    "X_test = X_test.astype(np.float32) / 255\n",
    "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
    "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "stacked_encoder = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(100, activation=\"selu\"),\n",
    "    keras.layers.Dense(30, activation=\"selu\"),\n",
    "])\n",
    "stacked_decoder = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"selu\", input_shape=[30]),\n",
    "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
    "    keras.layers.Reshape([28, 28])\n",
    "])\n",
    "stacked_ae = keras.models.Sequential([stacked_encoder, stacked_decoder])\n",
    "stacked_ae.compile(loss=\"binary_crossentropy\",\n",
    "                   optimizer=keras.optimizers.SGD(lr=1.5), metrics=['accuracy'])\n",
    "history = stacked_ae.fit(X_train, X_train, epochs=20,\n",
    "                         validation_data=(X_valid, X_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's look at the output reconstructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Helper function from Geron to show example reconstructions\n",
    "def show_reconstructions(model, images=X_valid, n_images=5):\n",
    "    reconstructions = model.predict(images[:n_images])\n",
    "    fig = plt.figure(figsize=(n_images * 1.5, 3))\n",
    "    for image_index in range(n_images):\n",
    "        plt.subplot(2, n_images, 1 + image_index)\n",
    "        plt.imshow(images[image_index], cmap=\"binary\", origin='upper')\n",
    "        plt.axis(\"off\")  \n",
    "        \n",
    "        plt.subplot(2, n_images, 1 + n_images + image_index)\n",
    "        plt.imshow(reconstructions[image_index], cmap=\"binary\", origin='upper')\n",
    "        plt.axis(\"off\")                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "show_reconstructions(stacked_ae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we can use t-SNE to visualize the clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "X_valid_compressed = stacked_encoder.predict(X_valid)\n",
    "tsne = TSNE()\n",
    "X_valid_2D = tsne.fit_transform(X_valid_compressed)\n",
    "X_valid_2D = (X_valid_2D - X_valid_2D.min()) / (X_valid_2D.max() - X_valid_2D.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# From Geron\n",
    "# adapted from https://scikit-learn.org/stable/auto_examples/manifold/plot_lle_digits.html\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 8))\n",
    "cmap = plt.cm.tab10\n",
    "plt.scatter(X_valid_2D[:, 0], X_valid_2D[:, 1], c=y_valid, s=10, cmap=cmap)\n",
    "image_positions = np.array([[1., 1.]])\n",
    "for index, position in enumerate(X_valid_2D):\n",
    "    dist = np.sum((position - image_positions) ** 2, axis=1)\n",
    "    if np.min(dist) > 0.02: # if far enough from other images\n",
    "        image_positions = np.r_[image_positions, [position]]\n",
    "        imagebox = mpl.offsetbox.AnnotationBbox(\n",
    "            mpl.offsetbox.OffsetImage(X_valid[index], cmap=\"binary\", origin='upper'),\n",
    "            position, bboxprops={\"edgecolor\": cmap(y_valid[index]), \"lw\": 2})\n",
    "        plt.gca().add_artist(imagebox)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Variational Autoencoders\n",
    "\n",
    "More common in astronomy are variational autoencoders, partly because the \"latent space\" that results from a standard autoencoder doesn't necessarily map continuously to the data (e.g., if your training data don't span the full data space).  We won't go into detail, just realize that these are something that you might try if you were otherwise going to try an autoencoder to tackle your problem.\n",
    "\n",
    "![Ivezic Figure 9.21](https://www.astroml.org/_images/fig_vae_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "[Geron17-12variational_autoencoder.png](attachment:Geron17-12variational_autoencoder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Variational Autoencoder Example\n",
    "\n",
    "Until GANs (see below), this is how you would have generated fake images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class Sampling(keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        mean, log_var = inputs\n",
    "        return K.random_normal(tf.shape(log_var)) * K.exp(log_var / 2) + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "codings_size = 10\n",
    "\n",
    "inputs = keras.layers.Input(shape=[28, 28])\n",
    "z = keras.layers.Flatten()(inputs)\n",
    "z = keras.layers.Dense(150, activation=\"selu\")(z)\n",
    "z = keras.layers.Dense(100, activation=\"selu\")(z)\n",
    "codings_mean = keras.layers.Dense(codings_size)(z)\n",
    "codings_log_var = keras.layers.Dense(codings_size)(z)\n",
    "codings = Sampling()([codings_mean, codings_log_var])\n",
    "variational_encoder = keras.models.Model(\n",
    "    inputs=[inputs], outputs=[codings_mean, codings_log_var, codings])\n",
    "\n",
    "decoder_inputs = keras.layers.Input(shape=[codings_size])\n",
    "x = keras.layers.Dense(100, activation=\"selu\")(decoder_inputs)\n",
    "x = keras.layers.Dense(150, activation=\"selu\")(x)\n",
    "x = keras.layers.Dense(28 * 28, activation=\"sigmoid\")(x)\n",
    "outputs = keras.layers.Reshape([28, 28])(x)\n",
    "variational_decoder = keras.models.Model(inputs=[decoder_inputs], outputs=[outputs])\n",
    "\n",
    "_, _, codings = variational_encoder(inputs)\n",
    "reconstructions = variational_decoder(codings)\n",
    "variational_ae = keras.models.Model(inputs=[inputs], outputs=[reconstructions])\n",
    "\n",
    "latent_loss = -0.5 * K.sum(\n",
    "    1 + codings_log_var - K.exp(codings_log_var) - K.square(codings_mean),\n",
    "    axis=-1)\n",
    "variational_ae.add_loss(K.mean(latent_loss) / 784.)\n",
    "variational_ae.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=['accuracy'])\n",
    "history = variational_ae.fit(X_train, X_train, epochs=20, batch_size=128,\n",
    "                             validation_data=(X_valid, X_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now generate some fake images.  Note that the goal here is NOT to teach you how to create \"deep fakes\", but rather to build up to scientifically useful applications of GANs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def plot_multiple_images(images, n_cols=None):\n",
    "    n_cols = n_cols or len(images)\n",
    "    n_rows = (len(images) - 1) // n_cols + 1\n",
    "    if images.shape[-1] == 1:\n",
    "        images = np.squeeze(images, axis=-1)\n",
    "    plt.figure(figsize=(n_cols, n_rows))\n",
    "    for index, image in enumerate(images):\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(image, cmap=\"binary\", origin='upper')\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "codings = tf.random.normal(shape=[12, codings_size])\n",
    "images = variational_decoder(codings).numpy()\n",
    "plot_multiple_images(images, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Generative Adversarial Networks (GANs)\n",
    "\n",
    "GANs are pure evil, see\n",
    "https://thispersondoesnotexist.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But they are also brilliant, incredibly useful, and relatively new (2014).  The idea builds logically on autoencoders in that we have a generator (like the decoder part of an autoencoder) that can produce fake data (e.g., an image).  Then we have a discriminator (a standard binary classifier) that tries to distinguish fake data from real.  Then the generator learns to produce more and more accurate images to trick the discriminator -- without ever seeing any real images -- it just has the feedback from the discriminator.\n",
    "\n",
    "[Geron17-15GAN.png](attachment:Geron17-15GAN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "[Geron17-18GANexample.png](attachment:Geron17-18GANexample.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For more, see\n",
    "https://towardsdatascience.com/understanding-generative-adversarial-networks-gans-cd6e4651a29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Astronomy has seen some interesting uses of autoencoders and GANs in recent years.  For example:\n",
    "    \n",
    "https://arxiv.org/abs/1702.00403    \n",
    "https://www.aanda.org/articles/aa/full_html/2017/07/aa30240-16/aa30240-16.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Generative Adversarial Network (GAN) example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "codings_size = 30\n",
    "\n",
    "generator = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"selu\", input_shape=[codings_size]),\n",
    "    keras.layers.Dense(150, activation=\"selu\"),\n",
    "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
    "    keras.layers.Reshape([28, 28])\n",
    "])\n",
    "discriminator = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(150, activation=\"selu\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "gan = keras.models.Sequential([generator, discriminator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
    "discriminator.trainable = False\n",
    "gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(1000)\n",
    "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def train_gan(gan, dataset, batch_size, codings_size, n_epochs=50):\n",
    "    generator, discriminator = gan.layers\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch + 1, n_epochs))              # not shown in the book\n",
    "        for X_batch in dataset:\n",
    "            # phase 1 - training the discriminator\n",
    "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "            generated_images = generator(noise)\n",
    "            X_fake_and_real = tf.concat([generated_images, X_batch], axis=0)\n",
    "            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
    "            discriminator.trainable = True\n",
    "            discriminator.train_on_batch(X_fake_and_real, y1)\n",
    "            # phase 2 - training the generator\n",
    "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "            y2 = tf.constant([[1.]] * batch_size)\n",
    "            discriminator.trainable = False\n",
    "            gan.train_on_batch(noise, y2)\n",
    "        plot_multiple_images(generated_images, 8)                     # not shown\n",
    "        plt.show()         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "train_gan(gan, dataset, batch_size, codings_size, n_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "generated_images = generator(noise)\n",
    "plot_multiple_images(generated_images, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Geron then runs the GAN for 50 epochs and discusses why training GANs is so hard and is still an active area of research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "More exciting to me is the possibility to use autoencoders for \"unsupervised pretraining\".  For example you have data that is only partially labeled (at least not enough to do traditional supervised classification).  We can train an autoencoder on the full data set, then used the encoder part as the base of a regular neural network that is trained on the labeled data that we do have.  See Geron Figure 17.6\n",
    "\n",
    "Also for [anomaly detection](https://scikit-learn.org/stable/modules/outlier_detection.html).\n",
    "See also\n",
    "https://www.pyimagesearch.com/2020/03/02/anomaly-detection-with-keras-tensorflow-and-deep-learning/ and \n",
    "https://towardsdatascience.com/autoencoder-neural-network-for-anomaly-detection-with-unlabeled-dataset-af9051a048."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The last example will pretend that we have a very large training set, but with only a small fraction of the training set having labels.  So, we will use tranfer learning from a pre-trained autoencoder that \"clusters\" all of the unlabeled training data to build the base layers of a our classification neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "[Geron17-6transferlearning.png](attachment:Geron17-6transferlearning.png)\n",
    "\n",
    "[Geron](./figures/Geron17-6transferlearning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This is exactly the problem that we have for quasar selection in LSST.  We have about 500k quasars that are labeled (plus labels for stars and galaxies) but those objects don't necessarily represent the full range of objects that we are trying to find.  So, it might help to use this pre-training technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We'll do this with Fashion MNIST data set as above.  Let's train the autoencoder with 2/3 of the full training set data (but without the labels!), which is 40k objects.  Then we'll have 10k for the test set, the validation set, and our \"B\" training set.  Then we'll see how that compares to a regular neural net trained with only the \"B\" training data.\n",
    "\n",
    "See \n",
    "https://github.com/ageron/handson-ml2/blob/master/11_training_deep_neural_networks.ipynb\n",
    "and\n",
    "https://github.com/ageron/handson-ml2/blob/master/17_autoencoders_and_gans.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session() #Make sure that we are starting a new model and not adding to an earlier one\n",
    "np.random.seed(42) #Set the numpy and tensorflow random seeds so that we all get the same answer\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#We'll use 60% of the sample to do unsupervised training with an autoencoder\n",
    "#Then 10% each for supervised training, validation, and testing\n",
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full.astype(np.float32) / 255\n",
    "X_test = X_test.astype(np.float32) / 255\n",
    "print(len(X_train_full),len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_A, X_rest, y_train_A, y_rest = train_test_split(X_train_full, y_train_full, test_size=0.33333, random_state=42)\n",
    "print(len(X_train_A),len(X_rest))\n",
    "\n",
    "X_train_B, X_valid, y_train_B, y_valid = train_test_split(X_rest, y_rest, test_size=0.50, random_state=42)\n",
    "print(len(X_train_B),len(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "stacked_encoder = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(200, activation=\"selu\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\"),\n",
    "    keras.layers.Dense(30, activation=\"selu\"),\n",
    "])\n",
    "stacked_decoder = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"selu\", input_shape=[30]),\n",
    "    keras.layers.Dense(200, activation=\"selu\", input_shape=[100]),\n",
    "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
    "    keras.layers.Reshape([28, 28])\n",
    "])\n",
    "stacked_ae = keras.models.Sequential([stacked_encoder, stacked_decoder])\n",
    "stacked_ae.compile(loss=\"binary_crossentropy\",\n",
    "                   optimizer=keras.optimizers.SGD(lr=1.5), metrics=['accuracy'])\n",
    "history = stacked_ae.fit(X_train_A, X_train_A, epochs=50,\n",
    "                         validation_data=(X_valid, X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "stacked_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "stacked_decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "stacked_ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "stacked_ae.save(\"autoencoder.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "#Maybe should be X_train_A if want to visualize clustering of autoencoder training results?\n",
    "#But plot validation objects on top?\n",
    "#X_valid_compressed = stacked_encoder.predict(X_valid)\n",
    "X_valid_compressed = stacked_encoder.predict(X_train_A)\n",
    "tsne = TSNE()\n",
    "X_valid_2D = tsne.fit_transform(X_valid_compressed)\n",
    "X_valid_2D = (X_valid_2D - X_valid_2D.min()) / (X_valid_2D.max() - X_valid_2D.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# From Geron\n",
    "# adapted from https://scikit-learn.org/stable/auto_examples/manifold/plot_lle_digits.html\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 8))\n",
    "cmap = plt.cm.tab10\n",
    "#plt.scatter(X_valid_2D[:, 0], X_valid_2D[:, 1], c=y_valid, s=10, cmap=cmap)\n",
    "plt.scatter(X_valid_2D[:, 0], X_valid_2D[:, 1], c=y_train_A, s=10, cmap=cmap)\n",
    "image_positions = np.array([[1., 1.]])\n",
    "for index, position in enumerate(X_valid_2D):\n",
    "    dist = np.sum((position - image_positions) ** 2, axis=1)\n",
    "    if np.min(dist) > 0.02: # if far enough from other images\n",
    "        image_positions = np.r_[image_positions, [position]]\n",
    "        imagebox = mpl.offsetbox.AnnotationBbox(\n",
    "            #mpl.offsetbox.OffsetImage(X_valid[index], cmap=\"binary\", origin='upper'),\n",
    "            mpl.offsetbox.OffsetImage(X_train_A[index], cmap=\"binary\", origin='upper'),\n",
    "            #position, bboxprops={\"edgecolor\": cmap(y_valid[index]), \"lw\": 2})\n",
    "            position, bboxprops={\"edgecolor\": cmap(y_train_A[index]), \"lw\": 2})\n",
    "        plt.gca().add_artist(imagebox)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model_A = keras.models.load_model(\"autoencoder.h5\") #Read in full autoencoder model\n",
    "#model_B_on_A = keras.models.Sequential(model_A.layers[:-1]) #Just take the encoder part\n",
    "#model_B_on_A.add(keras.layers.Dense(10, activation=\"softmax\")) #Now add on a new ouput layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Need to clone model A and set weights otherwise they will be update when fitting model_B_on_A\n",
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())\n",
    "\n",
    "model_B_on_A = keras.models.Sequential(model_A_clone.layers[:-1]) #Just take the encoder part\n",
    "model_B_on_A.add(keras.layers.Dense(10, activation=\"softmax\")) #Now add on a new ouput layer\n",
    "\n",
    "#Freeze reused layers during first few epochs\n",
    "#Later will have to unfreeze\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Now need to compile\n",
    "model_B_on_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Run for a few epochs\n",
    "#Here we need the answers; don't use data that trained autoencoder.\n",
    "#Might not be OK to use test data for validation here?\n",
    "history2 = model_B_on_A.fit(X_train_B, y_train_B, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Unfreeze reused layers\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Recompile with lower learning rate\n",
    "#Keep fitting for more epochs\n",
    "model_B_on_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                     metrics=[\"accuracy\"])\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=40,\n",
    "                           validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model_B_on_A.save(\"autoencoder_transfer_example.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model_B_on_A.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model_B = keras.models.Sequential() #Instantiate a sequential model\n",
    "model_B.add(keras.layers.Flatten(input_shape=[28, 28])) #Define the input layer\n",
    "model_B.add(keras.layers.Dense(300, activation=\"relu\")) #First hidden layer\n",
    "model_B.add(keras.layers.Dense(100, activation=\"relu\")) #Second hidden layer\n",
    "model_B.add(keras.layers.Dense(10, activation=\"softmax\")) #Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Now need to compile\n",
    "model_B.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "history_B = model_B.fit(X_train_B, y_train_B, epochs=50,\n",
    "                           validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model_B.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We find that Model B is actually better than Model A on B.  Geron says that this shouldn't be expected to work well with a small dense network.  Need a deeper network (maybe even CNN) to get best reslts.  But this at least shows how it is done.\n",
    "\n",
    "It is worth noting that we **do** have the answers for the full training set here, but if you did **NOT** then the 84.8% that we got (compared to 85.1%) is pretty darn good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "* Sigmoid needed for output of binary classification (with binary cross entropy loss)\n",
    "* ReLU for layers other than output\n",
    "* Softmax for output with more than 2 classes (with categorical cross entropy loss)\n",
    "\n",
    "multi-label is like doing several binary classifications at once, so use sigmoid activation function.\n",
    "\n",
    "One vs. rest\n",
    "\n",
    "Train faster with mini-batches.  Updates weights N mini-batches times per epoch.\n",
    "Batches normalize between layers.\n",
    "\n",
    "Current version leaves no place for AdaBoost or LogisticRegression."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "nbpresent": {
   "slides": {
    "a6340146-092b-47d0-8584-e84bb64c0952": {
     "id": "a6340146-092b-47d0-8584-e84bb64c0952",
     "prev": null,
     "regions": {
      "9f3c3dc8-1276-4b96-9b97-e4b352cc7fb5": {
       "attrs": {
        "height": 1,
        "width": 1,
        "x": 0.008349570712902259,
        "y": -0.008482103581361025
       },
       "id": "9f3c3dc8-1276-4b96-9b97-e4b352cc7fb5"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
